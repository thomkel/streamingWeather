package edu.uchicago.mpcs53013.streamingWeather;

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import scala.Function1;
import scala.Tuple2;
import scala.runtime.AbstractFunction1;

import com.google.common.collect.Lists;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;

import edu.uchicago.mpcs53013.flightSummary.FlightSummary;
import edu.uchicago.mpcs53013.weatherSummary.WeatherSummary;

import java.io.Serializable;
import java.util.Date;
import java.util.regex.Pattern;

import com.datastax.driver.core.Cluster;
import com.datastax.driver.core.Host;
import com.datastax.driver.core.Metadata;
import com.datastax.driver.core.ResultSet;
import com.datastax.driver.core.Row;
import com.datastax.driver.core.Session;
import com.datastax.spark.connector.cql.CassandraConnector;

import static com.datastax.spark.connector.japi.CassandraJavaUtil.javaFunctions;
import static com.datastax.spark.connector.japi.CassandraJavaUtil.mapToRow;
import static com.datastax.spark.connector.japi.CassandraJavaUtil.mapRowTo;

import org.apache.spark.Logging;
import org.apache.thrift.TDeserializer;
import org.apache.thrift.TException;
import org.apache.thrift.protocol.TJSONProtocol;
import org.apache.log4j.*;
/**
 * Counts words in UTF8 encoded, '\n' delimited text received from the network every second.
 *
 * Usage: JavaNetworkWordCount <hostname> <port>
 * <hostname> and <port> describe the TCP server that Spark Streaming would connect to receive data.
 *
 * To run this on your local machine, you need to first run a Netcat server
 * `$ nc -lk 9999`
 * and then run the example
 * `â€¢	bin/spark-submit --master spark://mpcs53013-VirtualBox:7077 --class edu.uchicago.mpcs53013.spark.JavaNetworkWordCount `
 */

public final class StreamingFlights implements Serializable {
	private static final Pattern SPACE = Pattern.compile(" ");
	static TDeserializer deserializer = new TDeserializer(new TJSONProtocol.Factory());
	public static void main(String[] args) {
		new StreamingFlights(args);
	}
	
	StreamingFlights(String[] args) {
		if (args.length < 3) {
			System.err.println("Usage: JavaStreamingWeather <hostname> <port> <Cassandra Host>");
			System.exit(1);
		}

		boolean log4jInitialized = Logger.getLogger("spark").getAllAppenders().hasMoreElements();
		 if (!log4jInitialized) {
			// We first log something to initialize Spark's default logging, then we override the
			// logging level.
			Logger.getLogger("spark").info("Setting log level to [WARN] for streaming example." +
			" To override add a custom log4j.properties to the classpath.");
			Logger.getLogger("spark").setLevel(Level.WARN);
			Logger.getRootLogger().setLevel(Level.WARN);
			}		
		// Create the context with a 1 second batch size
		final SparkConf sparkConf = new SparkConf().setAppName("StreamingFlights");
	    sparkConf.setMaster(args[2]);
		sparkConf.set("spark.cassandra.connection.host", args[3]);
		
		JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(1000));
        JavaSparkContext sc = new JavaSparkContext(sparkConf);

		// Create a JavaReceiverInputDStream on target ip:port and count the
		// words in input stream of \n delimited text (eg. generated by 'nc')
		// Note that no duplication in storage level only for running locally.
		// Replication necessary in distributed scenario for fault tolerance.
		JavaReceiverInputDStream<String> lines = ssc.socketTextStream(
				args[0], Integer.parseInt(args[1]), StorageLevels.MEMORY_AND_DISK_SER);
		JavaDStream<FlightSummary> flightSummaries 
		   = lines.map(new Function<String, FlightSummary>() {
			@Override
			public FlightSummary call(String x) {
				FlightSummary flightSummary = new FlightSummary();
				try {
					deserializer.fromString(flightSummary, x);
				} catch (TException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
				return flightSummary;
			}
		});
		    
		final CassandraConnector cassandraConnector = CassandraConnector.apply(sparkConf);
		JavaDStream<FlightAndWeatherSummary> flightAndWeatherSummaries
		 = flightSummaries.map(new Function<FlightSummary, FlightAndWeatherSummary>() {
			@Override
			public FlightAndWeatherSummary call(final FlightSummary flightSummary) {
				return cassandraConnector.withSessionDo(new AbstractFunction1<Session, FlightAndWeatherSummary>() {

					@Override
					public FlightAndWeatherSummary apply(Session session) {
						ResultSet results
						  = session.execute("SELECT * FROM weather.latest_weather WHERE STATION = "
								            + flightSummary.station + ";");
						
						// ignore data without latest_weather information
						if (results.isExhausted()){
							
//							FlightAndWeatherSummary flightAndWeatherSummary = new FlightAndWeatherSummary();
//							flightAndWeatherSummary.setOrigin(flightSummary.origin);
//							flightAndWeatherSummary.setDest(flightSummary.dest);
//							flightAndWeatherSummary.setWhen(new Date());
//							flightAndWeatherSummary.setDelay(flightSummary.delay);
//							return flightAndWeatherSummary;

							return null;
						}
						
						Row row = results.all().get(0);
						
						// ignore flight data with no origin, dest, or delay info
						if((flightSummary.origin == null) || (flightSummary.origin.equals("")) ||
								(flightSummary.dest == null) || (flightSummary.dest.equals("")) 
//								|| ((Integer)flightSummary.delay == null) || (flightSummary.delay != (Integer)flightSummary.delay))
								){
							return null;
						}
						
						FlightAndWeatherSummary flightAndWeatherSummary = new FlightAndWeatherSummary();
						flightAndWeatherSummary.setOrigin(flightSummary.origin);
						flightAndWeatherSummary.setDest(flightSummary.dest);
						flightAndWeatherSummary.setWhen(new Date());
						flightAndWeatherSummary.setDelay(flightSummary.delay);
						flightAndWeatherSummary.setFog(row.getBool("Fog"));
						flightAndWeatherSummary.setHail(row.getBool("Hail"));
						flightAndWeatherSummary.setRain(row.getBool("Rain"));
						flightAndWeatherSummary.setSnow(row.getBool("Snow"));
						flightAndWeatherSummary.setThunder(row.getBool("Thunder"));
						flightAndWeatherSummary.setTornado(row.getBool("Tornado"));
						return flightAndWeatherSummary; 
					}
					
					
				});
				
			}
		});		
		
        JavaDStream<FlightAndWeatherSummary>foundWeather 
        = flightAndWeatherSummaries.filter(new Function <FlightAndWeatherSummary, Boolean>(){
            public Boolean call(FlightAndWeatherSummary isWeather){
                if(isWeather == null){
                    return false;
                }else{
                    return true;    
                }
            }
        });

		javaFunctions(foundWeather)
          .writerBuilder("weather", "flight_and_weather", mapToRow(FlightAndWeatherSummary.class))
          .saveToCassandra();
		
		ssc.start();
		ssc.awaitTermination();
	}
}